{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição do desafio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Seu objetivo é realizar o processamento de uma base de dados com milhões de registros usando o Apache Spark. A base de dados contém informações sobre série histórica de preços de combustíveis no Brasil através da base de dados oferecida pelo Agência Nacional de Gás Natural e Biocombustíveis (ANP). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Configuração do ambiente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Caso você ainda não tenha o Apache Spark configurado em sua máquina, siga as instruções abaixo para configurar o ambiente. \n",
    "\n",
    "  Faça o download e instale o Apache Spark em sua máquina. Ele pode ser baixado no próprio https://spark.apache.org/downloads.html\n",
    "\n",
    ". Em seguida, extraia os arquivos do Apache para uma pasta de sua escolha. Depois, defina as variáveis de ambiente necessárias, como SPARK_HOME apontando para o diretório onde o Spark foi extraído e adicione o Spark ao PATH. Por fim, verifique se o Spark está instalado corretamente executando o comando spark-shell ou pyspark no terminal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Carregando os dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " baixe a base de dados no site de https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/serie-historica-de-precos-de-combustiveis\n",
    "\n",
    " . Este repositório contempla a base de dados histórica disponível da série de preços de combustíveis da Agência Nacional de Gás Natural e Biocombustíveis (ANP). O desafio consiste em realizar o download de todos os arquivos disponíveis dentro do repositório de dados abertos e então seguir com os próximos passos para processar estes dados através do Apache Spark, como apresentado durante as aulas. \n",
    "\n",
    "  É importante notar que as bases de dados estão segmentadas por tipo de combustí-vel, período (mensal ou semestral) e possuem histórico de 2004 à 2023. \n",
    "\n",
    "   Verifique o formato dos dados e escolha o mais apropriado para carregar no Apache Spark, como CSV, Parquet, JSON, etc. Utilize a API do Spark (DataFrame ou RDD) para carregar os dados em memória. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploração inicial dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Execute algumas operações básicas para explorar os dados, como count, show, schema, etc., para entender a estrutura e o conteúdo dos re-gistros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Realize as etapas necessárias de limpeza e trans-formação dos dados, como remoção de duplicatas, tratamento de valores ausentes, forma-tação de tipos de dados, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análises e insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Realize análises descritivas sobre os dados, como a distribuição de transações por categoria, análise temporal, etc., utilizando as transformações e opera-ções disponíveis no Apache Spark. Identifique os padrões e tendências nos dados e ex-traia insights relevantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otimização do processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Explore as opções de otimização do Apache Spark para lidar com o grande volume de dados, como particionamento adequado, uso de ca-ches, ajuste de configurações, etc., a fim de melhorar o desempenho do processamento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Utilize bibliotecas de visualização de dados, como Matplotlib ou Seaborn, para criar gráficos e visualizações dos insights obtidos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentação dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Documente todas as etapas realizadas, decisões tomadas e resultados obtidos em um relatório ou notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desafio extra (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Se você deseja um desafio adicional, tente realizar algu-ma análise preditiva nos dados, como a criação de um modelo de Machine Learning para prever fraudes em transações financeiras com base nos registros disponíveis. Lembre-se de que trabalhar com um volume de dados tão grande requer recursos adequados e co-nhecimentos avançados em Apache Spark. Portanto, certifique-se de ter o ambiente confi-gurado corretamente e conhecimento suficiente para lidar com o desafio proposto. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
